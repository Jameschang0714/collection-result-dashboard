import streamlit as st
import pandas as pd
import plotly.graph_objects as go
import numpy as np
from datetime import datetime

# Google Drive API imports
import google.oauth2.service_account
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseDownload
import io

# --- é é¢è¨­å®š (Page Config) ---
st.set_page_config(
    page_title="é›»å‚¬ç¸¾æ•ˆè¿½è¹¤æ­¸å› åˆ†æå„€è¡¨æ¿ (é›²ç«¯ç‰ˆ)",
    page_icon="ğŸ†",
    layout="wide"
)

# --- æ¨£å¼è¨­å®š (Custom CSS) ---
st.markdown("""
<style>
    .stMetric {
        border-radius: 10px;
        background-color: #f0f2f6;
        padding: 15px;
        border: 1px solid #e0e0e0;
    }
    .st-emotion-cache-1g8m2r4 { color: #0052cc; }
    .st-emotion-cache-1r4qj8v { font-size: 1.75rem; }
    .dataframe-container table { width: 100%; border-collapse: collapse; }
    .dataframe-container th, .dataframe-container td { text-align: left; padding: 8px; border-bottom: 1px solid #ddd; }
    .dataframe-container th { background-color: #f2f2f2; }
</style>
""", unsafe_allow_html=True)


# --- å¸¸é‡ç®¡ç† (Constants Management) ---
# DataFrame Column Names
COL_AGENT_ID = 'Agent ID'
COL_AGENT_NAME = 'å‚¬å“¡åç¨±'
COL_GROUP = 'çµ„åˆ¥'
COL_PAYMENT_DATE = 'payment_date'
COL_PAYMENT_AMOUNT = 'payment_amount'
COL_CALLS_IN_WINDOW = 'calls_in_window'
COL_CONNECTED_CALLS_IN_WINDOW = 'connected_calls_in_window'
COL_TALK_TIME_IN_WINDOW = 'talk_time_in_window'
COL_CASE_NO = 'Case No'
COL_DISPLAY_NAME = 'display_name'

# Metric Keys (Internal)
METRIC_TOTAL_COLLECTIONS = 'total_collections_closed'
METRIC_TOTAL_CALLS = 'total_calls'
METRIC_TOTAL_CONNECTED_CALLS = 'total_connected_calls'
METRIC_TOTAL_TALK_TIME = 'total_talk_time_sec'
METRIC_TOTAL_CASES = 'total_cases_handled'
METRIC_AVG_TOUCHES = 'avg_touches_per_collection'
METRIC_AVG_CONNECTED_TOUCHES = 'avg_connected_touches_per_case'
METRIC_EFFICIENCY_PER_CALL = 'efficiency_per_connected_call'
METRIC_EFFICIENCY_PER_HOUR = 'efficiency_per_hour'

# Metric Translations (Display)
METRICS_TRANSLATION = {
    'çµæ¡ˆå‚¬å›ç¸½é¡': METRIC_TOTAL_COLLECTIONS,
    'ç¸½æ’¥æ‰“é›»è©±æ•¸': METRIC_TOTAL_CALLS,
    'ç¸½æ¥é€šé›»è©±æ•¸': METRIC_TOTAL_CONNECTED_CALLS,
    'ç¸½é€šè©±æ™‚é•·': METRIC_TOTAL_TALK_TIME,
    'è™•ç†æ¡ˆä»¶ç¸½æ•¸': METRIC_TOTAL_CASES,
    'å¹³å‡æ’¥æ‰“æ¬¡æ•¸/æ¡ˆ': METRIC_AVG_TOUCHES,
    'å¹³å‡æ¥é€šæ¬¡æ•¸/æ¡ˆ': METRIC_AVG_CONNECTED_TOUCHES,
    'æ•ˆç‡ (é‡‘é¡/æœ‰æ•ˆé€šè©±)': METRIC_EFFICIENCY_PER_CALL,
    'æ•ˆç‡ (é‡‘é¡/å°æ™‚)': METRIC_EFFICIENCY_PER_HOUR,
}
REVERSE_METRICS_TRANSLATION = {v: k for k, v in METRICS_TRANSLATION.items()}


# --- è¼”åŠ©å‡½å¼ (Helper Functions) ---
def format_seconds_to_hms(seconds):
    if pd.isna(seconds) or not np.isfinite(seconds):
        return "00:00:00"
    seconds = int(seconds)
    hours, remainder = divmod(seconds, 3600)
    minutes, seconds = divmod(remainder, 60)
    return f"{hours:02d}:{minutes:02d}:{seconds:02d}"

def conditional_format(val):
    if isinstance(val, (int, float)):
        return f"{val:,.2f}"
    return str(val)

# --- æ•¸æ“šè¼‰å…¥èˆ‡å¿«å– (Data Loading & Caching) ---
@st.cache_data(ttl=3600) # Cache data for 1 hour
def load_data_from_gdrive(file_id, file_name):
    try:
        # Authenticate with Google Service Account
        creds_json = st.secrets["gcp_service_account"]
        creds = google.oauth2.service_account.Credentials.from_service_account_info(creds_json)
        
        service = build('drive', 'v3', credentials=creds)
        
        # Download the file
        request = service.files().get_media(fileId=file_id)
        fh = io.BytesIO()
        downloader = MediaIoBaseDownload(fh, request)
        done = False
        while done is False:
            status, done = downloader.next_chunk()
            st.spinner(f"Downloading {file_name}: {int(status.progress() * 100)}%.")
        
        fh.seek(0) # Rewind to the beginning of the file
        
        # Determine file type and read accordingly
        if file_name.endswith('.csv'):
            df = pd.read_csv(fh)
        elif file_name.endswith('.xlsx'):
            df = pd.read_excel(fh, engine='openpyxl')
        else:
            st.error(f"Unsupported file type for {file_name}. Only .csv and .xlsx are supported.")
            return None
        
        st.success(f"Successfully loaded {file_name} from Google Drive.")
        return df
        
    except Exception as e:
        st.error(f"Error loading {file_name} from Google Drive: {e}")
        st.info("è«‹ç¢ºèªæ‚¨çš„ Google Drive æª”æ¡ˆ ID å’Œæœå‹™å¸³è™Ÿé‡‘é‘°è¨­å®šæ­£ç¢ºã€‚")
        return None

@st.cache_data
def load_and_prep_data():
    try:
        # Get file IDs from Streamlit secrets
        ATTRIBUTION_FILE_ID = st.secrets["ATTRIBUTION_FILE_ID"]
        GROUP_LIST_FILE_ID = st.secrets["GROUP_LIST_FILE_ID"]

        # Load dataframes from Google Drive
        attr_df = load_data_from_gdrive(ATTRIBUTION_FILE_ID, "attribution_analysis.csv")
        group_df = load_data_from_gdrive(GROUP_LIST_FILE_ID, "åˆ†çµ„åå–®.xlsx")

        if attr_df is None or group_df is None:
            return None

        attr_df[COL_PAYMENT_DATE] = pd.to_datetime(attr_df[COL_PAYMENT_DATE])

        # --- Data Availability Check ---
        st.session_state['has_connected_calls_data'] = COL_CONNECTED_CALLS_IN_WINDOW in attr_df.columns and attr_df[COL_CONNECTED_CALLS_IN_WINDOW].notna().any()
        st.session_state['has_talk_time_data'] = COL_TALK_TIME_IN_WINDOW in attr_df.columns and attr_df[COL_TALK_TIME_IN_WINDOW].notna().any()
        
        # Ensure columns exist to prevent downstream errors
        if not st.session_state['has_connected_calls_data']:
            attr_df[COL_CONNECTED_CALLS_IN_WINDOW] = 0
        if not st.session_state['has_talk_time_data']:
            attr_df[COL_TALK_TIME_IN_WINDOW] = 0

        # Ensure column names for group_df are correct after loading from Google Drive
        group_df.columns = [COL_GROUP, COL_AGENT_ID, COL_AGENT_NAME] # Force column names

        merged_df = pd.merge(attr_df, group_df, on=COL_AGENT_ID, how='inner')
        return merged_df

    except KeyError as e:
        st.error(f"è«‹åœ¨ `.streamlit/secrets.toml` ä¸­è¨­å®šå¿…è¦çš„ Google Drive æª”æ¡ˆ ID æˆ–æœå‹™å¸³è™Ÿé‡‘é‘°: {e}")
        return None
    except Exception as e:
        st.error(f"è®€å–æˆ–è™•ç†æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤ï¼š{e}")
        return None

# --- å¯è¦–åŒ–åœ–è¡¨å‡½å¼ (Visualization Functions) ---
def create_performance_trend_chart(df, metric_col, time_unit, group_sizes, show_per_capita=True):
    if df.empty or metric_col not in df.columns:
        return go.Figure().update_layout(title_text='æ²’æœ‰è¶³å¤ çš„æ•¸æ“šç”Ÿæˆè¶¨å‹¢åœ–')
    
    df_copy = df.copy()
    df_copy = df_copy.set_index(COL_PAYMENT_DATE)
    
    unit_map = {'æ—¥': 'D', 'é€±': 'W'}
    resample_unit = unit_map.get(time_unit, 'D')
    
    metric_display_name = REVERSE_METRICS_TRANSLATION.get(metric_col, metric_col)
    
    total_metrics = [METRIC_TOTAL_COLLECTIONS, METRIC_TOTAL_CALLS, METRIC_TOTAL_CONNECTED_CALLS, METRIC_TOTAL_TALK_TIME, METRIC_TOTAL_CASES]
    is_total_metric = metric_col in total_metrics
    
    fig = go.Figure()
    
    yaxis_title = f'{time_unit} {metric_display_name}'
    if show_per_capita and is_total_metric:
        yaxis_title = f'{time_unit}äººå‡{metric_display_name}'

    for group in sorted(df_copy[COL_GROUP].unique()):
        group_df = df_copy[df_copy[COL_GROUP] == group]
        
        agg_dict = {
            METRIC_TOTAL_COLLECTIONS: 'sum',
            METRIC_TOTAL_CALLS: 'sum',
            METRIC_TOTAL_CONNECTED_CALLS: 'sum',
            METRIC_TOTAL_TALK_TIME: 'sum',
            METRIC_TOTAL_CASES: 'sum',
        }
        resampled_data = group_df.groupby(pd.Grouper(freq=resample_unit)).agg(agg_dict)

        resampled_data[METRIC_AVG_TOUCHES] = (resampled_data[METRIC_TOTAL_CALLS] / resampled_data[METRIC_TOTAL_CASES]).fillna(0)
        resampled_data[METRIC_AVG_CONNECTED_TOUCHES] = (resampled_data[METRIC_TOTAL_CONNECTED_CALLS] / resampled_data[METRIC_TOTAL_CASES]).fillna(0)
        resampled_data[METRIC_EFFICIENCY_PER_CALL] = (resampled_data[METRIC_TOTAL_COLLECTIONS] / resampled_data[METRIC_TOTAL_CONNECTED_CALLS]).replace([np.inf, -np.inf], 0).fillna(0)
        resampled_data[METRIC_EFFICIENCY_PER_HOUR] = (resampled_data[METRIC_TOTAL_COLLECTIONS] / (resampled_data[METRIC_TOTAL_TALK_TIME] / 3600)).replace([np.inf, -np.inf], 0).fillna(0)
        
        trend_data = resampled_data[metric_col]

        if show_per_capita and is_total_metric:
            group_size = group_sizes.get(group, 1)
            if group_size > 0:
                trend_data = trend_data / group_size

        fig.add_trace(go.Scatter(x=trend_data.index, y=trend_data.values, mode='lines+markers', name=group))
        
    fig.update_layout(
        title_text=f'åœ˜éšŠç¸¾æ•ˆè¶¨å‹¢åˆ†æ ({time_unit}è¦–è§’): {metric_display_name}',
        xaxis_title='æ—¥æœŸ',
        yaxis_title=yaxis_title,
        legend_title=COL_GROUP,
        font=dict(family="Arial, sans-serif", size=14)
    )
    return fig


def create_group_comparison_chart(df, metric_col):
    if df.empty or COL_GROUP not in df.columns or metric_col not in df.columns:
        return go.Figure().update_layout(title_text='æ²’æœ‰è¶³å¤ çš„æ•¸æ“šé€²è¡Œçµ„åˆ¥æ¯”è¼ƒ')
    metric_display_name = REVERSE_METRICS_TRANSLATION.get(metric_col, metric_col)
    group_performance = df.groupby(COL_GROUP)[metric_col].mean().sort_values(ascending=False)
    fig = go.Figure(go.Bar(x=group_performance.index, y=group_performance.values, text=group_performance.apply(lambda x: f'{x:,.2f}'), textposition='auto', marker_color='royalblue'))
    fig.update_layout(title_text=f'å„çµ„åˆ¥å¹³å‡ã€Œ{metric_display_name}ã€æ¯”è¼ƒ', xaxis_title=COL_GROUP, yaxis_title=f'å¹³å‡ {metric_display_name}', font=dict(family="Arial, sans-serif", size=14))
    return fig


def create_performance_matrix_chart(df, x_col, y_col):
    if df.empty or x_col not in df.columns or y_col not in df.columns:
        return go.Figure().update_layout(title_text='æ²’æœ‰æ•¸æ“šå¯ä¾›é¡¯ç¤º')
    
    if df[x_col].nunique() < 2 or df[y_col].nunique() < 2:
        return go.Figure().update_layout(title_text=f"æŒ‡æ¨™ç¼ºä¹è¶³å¤ è®Šç•°æ€§ï¼Œç„¡æ³•ç”Ÿæˆç¸¾æ•ˆçŸ©é™£", xaxis_title=REVERSE_METRICS_TRANSLATION.get(x_col, x_col), yaxis_title=REVERSE_METRICS_TRANSLATION.get(y_col, y_col))

    x_display = REVERSE_METRICS_TRANSLATION.get(x_col, x_col)
    y_display = REVERSE_METRICS_TRANSLATION.get(y_col, y_col)
    title = f"ç¸¾æ•ˆçŸ©é™£åˆ†æï¼š{y_display} vs. {x_display}"
    x_mean = df[x_col].mean()
    y_mean = df[y_col].mean()
    fig = go.Figure()
    for group in df[COL_GROUP].unique():
        group_df = df[df[COL_GROUP] == group]
        fig.add_trace(go.Scatter(x=group_df[x_col], y=group_df[y_col], mode='markers', name=group, customdata=group_df[[COL_AGENT_ID, COL_AGENT_NAME]], hovertemplate=("<b>å‚¬å“¡:</b> %{customdata[1]} (%{customdata[0]})<br>" + f"<b>{x_display}:</b> %{{x:,.2f}}<br>" + f"<b>{y_display}:</b> %{{y:,.2f}}<extra></extra>"), marker=dict(size=12, line=dict(width=1), opacity=0.8)))
    fig.add_shape(type="line", x0=df[x_col].min(), y0=y_mean, x1=df[x_col].max(), y1=y_mean, line=dict(color="grey", width=2, dash="dash"), name="Y å¹³å‡")
    fig.add_shape(type="line", x0=x_mean, y0=df[y_col].min(), x1=x_mean, y1=df[y_col].max(), line=dict(color="grey", width=2, dash="dash"), name="X å¹³å‡")
    is_y_cost_metric = y_col in [] 
    if is_y_cost_metric:
        q1_name, q2_name, q3_name, q4_name = "é‡é»è¼”å°å€", "å‹¤å¥®æ¢ç´¢å€", "æ½›åŠ›ç¨®å­å€", "é«˜æ•ˆæ˜æ˜Ÿå€"
    else:
        q1_name, q2_name, q3_name, q4_name = "æ½›åŠ›ç¨®å­å€", "é«˜æ•ˆæ˜æ˜Ÿå€", "é‡é»è¼”å°å€", "å‹¤å¥®æ¢ç´¢å€"
    fig.add_annotation(x=x_mean, y=df[y_col].max(), xref="x", yref="y", text=q2_name, showarrow=False, xanchor='left', yanchor='top', font=dict(color="grey", size=12), align="left")
    fig.add_annotation(x=x_mean, y=df[y_col].min(), xref="x", yref="y", text=q3_name, showarrow=False, xanchor='left', yanchor='bottom', font=dict(color="grey", size=12), align="left")
    fig.add_annotation(x=df[x_col].min(), y=y_mean, xref="x", yref="y", text=q1_name, showarrow=False, xanchor='left', yanchor='top', font=dict(color="grey", size=12), align="left")
    fig.add_annotation(x=df[x_col].max(), y=y_mean, xref="x", yref="y", text=q4_name, showarrow=False, xanchor='right', yanchor='top', font=dict(color="grey", size=12), align="right")
    fig.update_layout(title_text=title, xaxis_title=x_display, yaxis_title=y_display, legend_title=COL_GROUP, font=dict(family="Arial, sans-serif", size=14), height=600)
    return fig

def create_coaching_radar_chart(df, coached_agent_id, coached_agent_display_name, benchmark_agents, scaling_method='rank'):
    metrics = [m for m in METRICS_TRANSLATION.values() if m in df.columns]
    df_normalized = df.copy()
    
    if scaling_method == 'rank':
        for col in metrics:
            df_normalized[col] = df[col].rank(pct=True)
    else:
        for col in metrics:
            df_normalized[f'{col}_log'] = np.log1p(df[col])
            min_val = df_normalized[f'{col}_log'].min()
            max_val = df_normalized[f'{col}_log'].max()
            if (max_val - min_val) > 0:
                df_normalized[col] = (df_normalized[f'{col}_log'] - min_val) / (max_val - min_val)
            else:
                df_normalized[col] = 0.5
    
    theta_labels = [REVERSE_METRICS_TRANSLATION.get(m, m) for m in metrics]
    fig = go.Figure()

    coached_raw_data = df[df[COL_AGENT_ID] == coached_agent_id][metrics].iloc[0]
    coached_normalized_data = df_normalized[df_normalized[COL_AGENT_ID] == coached_agent_id][metrics].iloc[0]
    
    def format_hover_text(metric_key, raw_value, rank_val):
        metric_name = REVERSE_METRICS_TRANSLATION[metric_key]
        if metric_key in [METRIC_TOTAL_COLLECTIONS, METRIC_EFFICIENCY_PER_CALL, METRIC_EFFICIENCY_PER_HOUR]:
            formatted_value = f"${raw_value:,.0f}"
        elif metric_key in [METRIC_TOTAL_CALLS, METRIC_TOTAL_CONNECTED_CALLS, METRIC_TOTAL_CASES, METRIC_TOTAL_TALK_TIME]:
            formatted_value = f"{raw_value:,.0f}"
        else:
            formatted_value = f"{raw_value:,.2f}"
        return f"{metric_name}: {formatted_value}<br>(åœ˜éšŠæ’å: Top {rank_val:.0%})"

    hovertemplate_coached = [format_hover_text(label, raw_value, coached_normalized_data[label]) for label, raw_value in coached_raw_data.items()]

    r_coached = list(coached_normalized_data.values)
    r_coached.append(r_coached[0])
    theta_labels_closed = list(theta_labels)
    theta_labels_closed.append(theta_labels_closed[0])
    hovertemplate_coached.append(hovertemplate_coached[0])
    
    fig.add_trace(go.Scatterpolar(
        r=r_coached, theta=theta_labels_closed, fill='toself', name=f'å—è¼”å°äººå“¡: {coached_agent_display_name}',
        line=dict(color='deepskyblue'), fillcolor='rgba(0, 191, 255, 0.5)',
        customdata=hovertemplate_coached, hovertemplate='%{customdata}<extra></extra>'
    ))

    benchmark_df_raw = df[df[COL_AGENT_ID].isin(benchmark_agents)]
    benchmark_avg_raw_data = benchmark_df_raw[metrics].mean()
    benchmark_df_normalized = df_normalized[df_normalized[COL_AGENT_ID].isin(benchmark_agents)]
    benchmark_avg_normalized_data = benchmark_df_normalized[metrics].mean()
    
    hovertemplate_benchmark = [format_hover_text(label, raw_value, benchmark_avg_normalized_data[label]) for label, raw_value in benchmark_avg_raw_data.items()]

    r_benchmark = list(benchmark_avg_normalized_data.values)
    r_benchmark.append(r_benchmark[0])
    hovertemplate_benchmark.append(hovertemplate_benchmark[0])

    fig.add_trace(go.Scatterpolar(
        r=r_benchmark, theta=theta_labels_closed, fill='none', name='æ¨™ç«¿ç¾¤çµ„å¹³å‡',
        line=dict(color='red', dash='dash'), customdata=hovertemplate_benchmark,
        hovertemplate='%{customdata}<extra></extra>'
    ))

    fig.update_layout(polar=dict(radialaxis=dict(visible=True, range=[0, 1])), showlegend=True, title=dict(text=f'{coached_agent_display_name} vs. æ¨™ç«¿ç¾¤çµ„ç¸¾æ•ˆå‰–æ', font=dict(size=20)), height=600)
    return fig, coached_raw_data, benchmark_avg_raw_data

# --- REFACTORED/NEW FUNCTION ---
def create_agent_deep_dive_distribution_chart(raw_df, agent_id, benchmark_ids, agent_display_name, threshold, metric_to_analyze):
    """
    å»ºç«‹ä¸€å€‹åˆ†ä½ˆåœ–ï¼Œç”¨æ–¼æ¯”è¼ƒå€‹äººèˆ‡æ¨™ç«¿ç¾¤çµ„åœ¨ä¸åŒæŒ‡æ¨™ï¼ˆé€šè©±æ¬¡æ•¸ã€é€šè©±æ™‚é•·ï¼‰ä¸Šçš„å·¥ä½œæ¨¡å¼ã€‚
    """
    fig = go.Figure()
    y_max = 0

    # æ ¹æ“šé¸æ“‡çš„æŒ‡æ¨™ï¼Œè¨­å®šå°æ‡‰çš„æ¬„ä½åç¨±å’Œé¡¯ç¤ºåç¨±
    if metric_to_analyze == 'ç¸½æ’¥æ‰“æ¬¡æ•¸':
        metric_col = COL_CALLS_IN_WINDOW
        metric_display = 'ç¸½æ’¥æ‰“æ¬¡æ•¸'
        xaxis_title = f'å–®ä¸€æ¡ˆä»¶æ‰€éœ€{metric_display}'
    elif metric_to_analyze == 'ç¸½æ¥é€šæ¬¡æ•¸':
        metric_col = COL_CONNECTED_CALLS_IN_WINDOW
        metric_display = 'ç¸½æ¥é€šæ¬¡æ•¸'
        xaxis_title = f'å–®ä¸€æ¡ˆä»¶æ‰€éœ€{metric_display}'
    elif metric_to_analyze == 'é€šè©±æ™‚é•·':
        metric_col = COL_TALK_TIME_IN_WINDOW
        metric_display = 'é€šè©±æ™‚é•·'
        xaxis_title = f'å–®ä¸€æ¡ˆä»¶{metric_display} (ç§’)'
    else:
        return go.Figure().update_layout(title_text='ç„¡æ•ˆçš„åˆ†ææŒ‡æ¨™')

    # éæ¿¾æ‰è¶…éé–¾å€¼çš„æ•¸æ“š
    filtered_raw_df = raw_df[raw_df[metric_col] <= threshold]
    
    # è™•ç†è¢«åˆ†æäººå“¡çš„æ•¸æ“š
    agent_df = filtered_raw_df[filtered_raw_df[COL_AGENT_ID] == agent_id]
    agent_avg_metric = 0
    if not agent_df.empty and agent_df[metric_col].sum() > 0:
        if metric_to_analyze in ['ç¸½æ’¥æ‰“æ¬¡æ•¸', 'ç¸½æ¥é€šæ¬¡æ•¸']:
            agent_counts = agent_df[agent_df[metric_col] > 0][metric_col].value_counts().sort_index()
        else: # é€šè©±æ™‚é•·åˆ†ç®±è™•ç†
            bins = np.arange(0, threshold + 31, 30)
            labels = [f'{i}-{i+30}' for i in bins[:-1]]
            agent_df['time_bin'] = pd.cut(agent_df[metric_col], bins=bins, labels=labels, right=False)
            agent_counts = agent_df['time_bin'].value_counts().sort_index()

        if not agent_counts.empty:
            y_max = agent_counts.values.max()
            fig.add_trace(go.Bar(x=agent_counts.index.astype(str), y=agent_counts.values, name=f'{agent_display_name} (æ¡ˆä»¶æ•¸)', text=agent_counts.values, textposition='auto', marker_color='darkcyan'))
            agent_avg_metric = agent_df[agent_df[metric_col] > 0][metric_col].mean()

    # è™•ç†æ¨™ç«¿ç¾¤çµ„çš„æ•¸æ“š
    benchmark_avg_metric = 0
    if benchmark_ids:
        benchmark_df = filtered_raw_df[filtered_raw_df[COL_AGENT_ID].isin(benchmark_ids)]
        if not benchmark_df.empty and benchmark_df[metric_col].sum() > 0:
            if metric_to_analyze in ['ç¸½æ’¥æ‰“æ¬¡æ•¸', 'ç¸½æ¥é€šæ¬¡æ•¸']:
                benchmark_counts = benchmark_df[benchmark_df[metric_col] > 0][metric_col].value_counts()
            else: # é€šè©±æ™‚é•·åˆ†ç®±è™•ç†
                bins = np.arange(0, threshold + 31, 30)
                labels = [f'{i}-{i+30}' for i in bins[:-1]]
                benchmark_df['time_bin'] = pd.cut(benchmark_df[metric_col], bins=bins, labels=labels, right=False)
                benchmark_counts = benchmark_df['time_bin'].value_counts()
            
            num_benchmark_agents = len(benchmark_ids)
            avg_benchmark_counts = (benchmark_counts / num_benchmark_agents).sort_index()
            
            if not avg_benchmark_counts.empty:
                y_max = max(y_max, avg_benchmark_counts.values.max())
                fig.add_trace(go.Scatter(x=avg_benchmark_counts.index.astype(str), y=avg_benchmark_counts.values, name='æ¨™ç«¿ç¾¤çµ„ (å¹³å‡æ¡ˆä»¶æ•¸/äºº)', mode='lines+markers', line=dict(color='red', dash='dash')))
            benchmark_avg_metric = benchmark_df[benchmark_df[metric_col] > 0][metric_col].mean()

    # æ·»åŠ å¹³å‡å€¼æ¨™ç¤ºç·š
    if agent_avg_metric > 0:
        avg_text = f"å€‹äººå¹³å‡: {agent_avg_metric:.2f}"
        if metric_to_analyze == 'é€šè©±æ™‚é•·':
             avg_text += "s"
        fig.add_shape(type="line", x0=-0.5, y0=agent_avg_metric if metric_to_analyze != 'é€šè©±æ™‚é•·' else None, x1=len(agent_counts)-0.5 if 'agent_counts' in locals() and not agent_counts.empty else 0, y1=agent_avg_metric if metric_to_analyze != 'é€šè©±æ™‚é•·' else None, line=dict(color="deepskyblue", width=2, dash="dot"), yref='y' if metric_to_analyze != 'é€šè©±æ™‚é•·' else 'paper')
        # The annotation logic needs to be smarter for binned data
        # For simplicity, we skip annotating average line for binned data for now.

    if benchmark_avg_metric > 0:
        avg_text = f"æ¨™ç«¿å¹³å‡: {benchmark_avg_metric:.2f}"
        if metric_to_analyze == 'é€šè©±æ™‚é•·':
             avg_text += "s"
        # Similar annotation complexity for binned data.
        
    if y_max == 0:
        return go.Figure().update_layout(title_text=f'åœ¨æ­¤æ¢ä»¶ä¸‹ç„¡æœ‰æ•ˆçµæ¡ˆæ¡ˆä»¶')
        
    fig.update_layout(
        title_text=f'<b>{agent_display_name}</b> vs. æ¨™ç«¿ç¾¤çµ„å·¥ä½œæ¨¡å¼æ¯”è¼ƒ ({metric_display})', 
        xaxis_title=xaxis_title, 
        yaxis_title='æ¡ˆä»¶æ•¸é‡', 
        font=dict(family="Arial, sans-serif", size=14), 
        legend=dict(orientation="h", yanchor="bottom", y=1.02, xanchor="right", x=1), 
        height=500, 
        barmode='group'
    )
    return fig


def create_payment_distribution_chart(raw_df, agent_id, benchmark_ids, agent_display_name):
    """
    å»ºç«‹ä¸€å€‹ç®±å‹åœ–ä¾†æ¯”è¼ƒå€‹äººèˆ‡æ¨™ç«¿ç¾¤çµ„çš„æ¡ˆä»¶åƒ¹å€¼åˆ†ä½ˆã€‚
    """
    fig = go.Figure()

    # å–å¾—è¢«åˆ†æäººå“¡çš„æ•¸æ“š
    agent_df = raw_df[raw_df[COL_AGENT_ID] == agent_id]
    if not agent_df.empty:
        fig.add_trace(go.Box(
            y=agent_df[COL_PAYMENT_AMOUNT],
            name=agent_display_name,
            marker_color='darkcyan',
            boxpoints='all', # é¡¯ç¤ºæ‰€æœ‰æ•¸æ“šé»
            jitter=0.3,
            pointpos=-1.8
        ))

    # å–å¾—æ¨™ç«¿ç¾¤çµ„çš„æ•¸æ“š
    if benchmark_ids:
        benchmark_df = raw_df[raw_df[COL_AGENT_ID].isin(benchmark_ids)]
        if not benchmark_df.empty:
            fig.add_trace(go.Box(
                y=benchmark_df[COL_PAYMENT_AMOUNT],
                name='æ¨™ç«¿ç¾¤çµ„',
                marker_color='tomato',
                boxpoints='all',
                jitter=0.3,
                pointpos=-1.8
            ))

    if agent_df.empty and (not benchmark_ids or benchmark_df.empty):
        return go.Figure().update_layout(title_text='æ²’æœ‰è¶³å¤ çš„æ¡ˆä»¶æ•¸æ“šå¯ä¾›åˆ†æåƒ¹å€¼åˆ†ä½ˆ')

    fig.update_layout(
        title_text=f'<b>{agent_display_name}</b> vs. æ¨™ç«¿ç¾¤çµ„æ¡ˆä»¶åƒ¹å€¼åˆ†ä½ˆæ¯”è¼ƒ',
        yaxis_title='å–®æ¡ˆå‚¬å›é‡‘é¡ ($)',
        font=dict(family="Arial, sans-serif", size=14),
        showlegend=False # ç®±å‹åœ–çš„åç¨±æœƒé¡¯ç¤ºåœ¨Xè»¸ä¸Š
    )
    return fig

# --- ä¸»æ‡‰ç”¨ç¨‹å¼ä»‹é¢ (Main App Interface) ---

st.title("ğŸ“Š é›»å‚¬ç¸¾æ•ˆè¿½è¹¤æ­¸å› åˆ†æå„€è¡¨æ¿ (é›²ç«¯ç‰ˆ)")
st.caption("ä¸€å€‹æ•´åˆäº†æ™‚é–“åºåˆ—åˆ†æèˆ‡è³ªæ•ˆè©•ä¼°çš„æ±ºç­–æ”¯æ´å¹³å°")

try:
    df_raw = load_and_prep_data()
except Exception as e:
    st.error(f"å„€è¡¨æ¿å•Ÿå‹•å¤±æ•—ï¼š{e}")
    df_raw = None

if df_raw is not None:
    st.sidebar.header("âš™ï¸ æ§åˆ¶é¢æ¿")
    
    st.sidebar.subheader("é¸æ“‡åˆ†ææ—¥æœŸå€é–“")
    min_date = df_raw[COL_PAYMENT_DATE].min().date()
    max_date = df_raw[COL_PAYMENT_DATE].max().date()
    start_date = st.sidebar.date_input("é–‹å§‹æ—¥æœŸ", min_date, min_value=min_date, max_value=max_date)
    end_date = st.sidebar.date_input("çµæŸæ—¥æœŸ", max_date, min_value=start_date, max_value=max_date)

    date_filtered_raw_df = df_raw[(df_raw[COL_PAYMENT_DATE].dt.date >= start_date) & (df_raw[COL_PAYMENT_DATE].dt.date <= end_date)].copy()

    agent_summary_df = pd.DataFrame()
    daily_summary_df = pd.DataFrame()
    group_sizes = {}

    if not date_filtered_raw_df.empty:
        rename_dict = {
            COL_PAYMENT_AMOUNT: METRIC_TOTAL_COLLECTIONS,
            COL_CALLS_IN_WINDOW: METRIC_TOTAL_CALLS,
            COL_CONNECTED_CALLS_IN_WINDOW: METRIC_TOTAL_CONNECTED_CALLS,
            COL_TALK_TIME_IN_WINDOW: METRIC_TOTAL_TALK_TIME,
            COL_CASE_NO: METRIC_TOTAL_CASES
        }
        
        daily_agg_funcs = {
            COL_PAYMENT_AMOUNT: 'sum', COL_CALLS_IN_WINDOW: 'sum', 
            COL_CONNECTED_CALLS_IN_WINDOW: 'sum', COL_TALK_TIME_IN_WINDOW: 'sum', 
            COL_CASE_NO: 'nunique'
        }
        daily_summary_df = date_filtered_raw_df.groupby([COL_AGENT_ID, COL_AGENT_NAME, COL_GROUP, pd.Grouper(key=COL_PAYMENT_DATE, freq='D')]).agg(daily_agg_funcs).reset_index()
        daily_summary_df.rename(columns=rename_dict, inplace=True)
        
        agent_agg_funcs = {
            COL_PAYMENT_AMOUNT: 'sum', COL_CALLS_IN_WINDOW: 'sum', 
            COL_CONNECTED_CALLS_IN_WINDOW: 'sum', COL_TALK_TIME_IN_WINDOW: 'sum', 
            COL_CASE_NO: 'nunique'
        }
        agent_summary_df = date_filtered_raw_df.groupby([COL_AGENT_ID, COL_AGENT_NAME, COL_GROUP]).agg(agent_agg_funcs).reset_index()
        agent_summary_df.rename(columns=rename_dict, inplace=True)
        
        agent_summary_df[METRIC_AVG_TOUCHES] = (agent_summary_df[METRIC_TOTAL_CALLS] / agent_summary_df[METRIC_TOTAL_CASES]).fillna(0)
        agent_summary_df[METRIC_AVG_CONNECTED_TOUCHES] = (agent_summary_df[METRIC_TOTAL_CONNECTED_CALLS] / agent_summary_df[METRIC_TOTAL_CASES]).fillna(0)
        agent_summary_df[METRIC_EFFICIENCY_PER_CALL] = (agent_summary_df[METRIC_TOTAL_COLLECTIONS] / agent_summary_df[METRIC_TOTAL_CONNECTED_CALLS]).replace([np.inf, -np.inf], 0).fillna(0)
        agent_summary_df[METRIC_EFFICIENCY_PER_HOUR] = (agent_summary_df[METRIC_TOTAL_COLLECTIONS] / (agent_summary_df[METRIC_TOTAL_TALK_TIME] / 3600)).replace([np.inf, -np.inf], 0).fillna(0)
        
        group_sizes = agent_summary_df.groupby(COL_GROUP)[COL_AGENT_ID].nunique()

    st.sidebar.subheader("åœ˜éšŠèˆ‡äººå“¡ç¯©é¸")
    
    if not agent_summary_df.empty:
        all_groups = sorted(agent_summary_df[COL_GROUP].unique())
        selected_groups = st.sidebar.multiselect('é¸æ“‡æ¯”è¼ƒçµ„åˆ¥ (å¯å¤šé¸)', options=all_groups, default=all_groups)
    else:
        selected_groups = []

    if selected_groups:
        filtered_df = agent_summary_df[agent_summary_df[COL_GROUP].isin(selected_groups)]
        filtered_daily_df = daily_summary_df[daily_summary_df[COL_GROUP].isin(selected_groups)]
    else:
        filtered_df = pd.DataFrame(columns=agent_summary_df.columns)
        filtered_daily_df = pd.DataFrame(columns=daily_summary_df.columns)

    if not filtered_df.empty:
        filtered_df[COL_DISPLAY_NAME] = filtered_df[COL_AGENT_ID] + " (" + filtered_df[COL_AGENT_NAME] + ")"
        agent_display_list = ['å…¨é«”'] + sorted(filtered_df[COL_DISPLAY_NAME].unique())
    else:
        agent_display_list = ['å…¨é«”']
    selected_display_name = st.sidebar.selectbox('é¸æ“‡å‚¬æ”¶å“¡', agent_display_list)

    if selected_display_name != 'å…¨é«”':
        final_filtered_df = filtered_df[filtered_df[COL_DISPLAY_NAME] == selected_display_name]
    else:
        final_filtered_df = filtered_df

    tab1, tab2, tab3, tab4 = st.tabs(["ç¸¾æ•ˆç¸½è¦½", "è¡Œç‚ºæ­¸å› çŸ©é™£", "ç¸¾æ•ˆè³¦èƒ½", "å‚¬å“¡æ·±åº¦å‰–æ"])

    with tab1:
        st.header("ç¸¾æ•ˆç¸½è¦½ (KPI Overview)")
        if not final_filtered_df.empty:
            st.subheader("é—œéµç¸¾æ•ˆæŒ‡æ¨™ (KPIs)")
            kpi_cols = st.columns(5)
            kpi_cols[0].metric("ç¸½çµæ¡ˆå‚¬å›é‡‘é¡", f"${final_filtered_df[METRIC_TOTAL_COLLECTIONS].sum():,.0f}")
            kpi_cols[1].metric("ç¸½è™•ç†æ¡ˆä»¶æ•¸", f"{final_filtered_df[METRIC_TOTAL_CASES].sum():,.0f}")
            kpi_cols[2].metric("å¹³å‡æ’¥æ‰“æ¬¡æ•¸/æ¡ˆ", f"{final_filtered_df[METRIC_AVG_TOUCHES].mean():.2f}")
            if st.session_state.get('has_connected_calls_data'):
                kpi_cols[3].metric("æ•ˆç‡ (é‡‘é¡/æœ‰æ•ˆé€šè©±)", f"${final_filtered_df[METRIC_EFFICIENCY_PER_CALL].mean():,.0f}")
            kpi_cols[4].metric("æ•ˆç‡ (é‡‘é¡/å°æ™‚)", f"${final_filtered_df[METRIC_EFFICIENCY_PER_HOUR].mean():,.0f}")
            st.markdown("---")
            
            if len(selected_groups) > 1 and selected_display_name == 'å…¨é«”':
                st.subheader("åœ˜éšŠç¸¾æ•ˆæ¯”è¼ƒ")
                comparison_metric_options = [m for m in METRICS_TRANSLATION.keys() if METRICS_TRANSLATION[m] in filtered_df.columns]
                comparison_metric_display_name = st.selectbox("é¸æ“‡æ¯”è¼ƒæŒ‡æ¨™", options=comparison_metric_options, index=0)
                comparison_metric_col_name = METRICS_TRANSLATION[comparison_metric_display_name]
                st.plotly_chart(create_group_comparison_chart(filtered_df, comparison_metric_col_name), use_container_width=True)

            st.markdown("---")
            st.subheader("ç¸¾æ•ˆè¶¨å‹¢åˆ†æ")
            col1, col2 = st.columns([1, 3])
            with col1:
                trend_metric_display = st.selectbox("é¸æ“‡è¶¨å‹¢æŒ‡æ¨™", options=[k for k, v in METRICS_TRANSLATION.items() if v in agent_summary_df.columns])
                trend_metric_col = METRICS_TRANSLATION[trend_metric_display]
                time_unit_selection = st.radio("é¸æ“‡æ™‚é–“é¡†ç²’åº¦", ('æ—¥', 'é€±'), horizontal=True)
                show_per_capita = st.checkbox("ä»¥äººå‡å€¼é¡¯ç¤ºè¶¨å‹¢", value=True)
            with col2:
                st.plotly_chart(create_performance_trend_chart(filtered_daily_df, trend_metric_col, time_unit_selection, group_sizes, show_per_capita), use_container_width=True)
        else:
            st.info("åœ¨é¸å®šçš„æ¢ä»¶ä¸‹æ²’æœ‰æ•¸æ“šå¯é¡¯ç¤ºã€‚")

    with tab2:
        st.header("è¡Œç‚ºæ­¸å› åˆ†æ (Behavioral Analysis)")
        if not filtered_df.empty:
            st.write("é€éäº’å‹•å¼ç¸¾æ•ˆçŸ©é™£ï¼Œæ¢ç´¢ä¸åŒè¡Œç‚ºæŒ‡æ¨™èˆ‡æˆæœæŒ‡æ¨™ä¹‹é–“çš„é—œè¯æ€§ï¼Œä¸¦è‡ªå‹•è­˜åˆ¥äººå“¡åˆ†ä½ˆè±¡é™ã€‚")
            metrics_options = [m for m in METRICS_TRANSLATION.values() if m in filtered_df.columns]
            col1, col2 = st.columns(2)
            with col1:
                x_axis = st.selectbox("é¸æ“‡ X è»¸æŒ‡æ¨™", options=metrics_options, index=metrics_options.index(METRIC_TOTAL_CALLS) if METRIC_TOTAL_CALLS in metrics_options else 0, key="ax_matrix", format_func=lambda x: REVERSE_METRICS_TRANSLATION.get(x, x))
            with col2:
                y_axis_default_index = metrics_options.index(METRIC_AVG_TOUCHES) if METRIC_AVG_TOUCHES in metrics_options else 0
                y_axis = st.selectbox("é¸æ“‡ Y è»¸æŒ‡æ¨™", options=metrics_options, index=y_axis_default_index, key="ay_matrix", format_func=lambda x: REVERSE_METRICS_TRANSLATION.get(x, x))
            st.plotly_chart(create_performance_matrix_chart(filtered_df, x_axis, y_axis), use_container_width=True)
        else:
            st.info("åœ¨é¸å®šçš„æ¢ä»¶ä¸‹æ²’æœ‰æ•¸æ“šå¯é¡¯ç¤ºã€‚")

    with tab3:
        st.header("ç¸¾æ•ˆè³¦èƒ½ (Coaching Module)")
        st.write("é¸æ“‡ä¸€ä½å—è¼”å°äººå“¡ï¼Œä¸¦èˆ‡ä¸€å€‹æˆ–å¤šå€‹æ¨™ç«¿äººå“¡çµ„æˆçš„ç¾¤çµ„å¹³å‡ç¸¾æ•ˆé€²è¡Œæ¯”è¼ƒã€‚")
        if not filtered_df.empty and len(filtered_df[COL_AGENT_ID].unique()) > 1:
            agent_select_df = filtered_df[[COL_AGENT_ID, COL_AGENT_NAME]].drop_duplicates()
            agent_select_df[COL_DISPLAY_NAME] = agent_select_df[COL_AGENT_ID] + " (" + agent_select_df[COL_AGENT_NAME] + ")"
            agent_id_map = agent_select_df.set_index(COL_DISPLAY_NAME)[COL_AGENT_ID]
            display_name_list = sorted(agent_select_df[COL_DISPLAY_NAME].unique())
            
            if 'benchmark_select' not in st.session_state:
                st.session_state.benchmark_select = []

            col1, col2 = st.columns(2)
            with col1:
                coached_display_name = st.selectbox("é¸æ“‡å—è¼”å°äººå“¡", options=display_name_list, key="coach_select")
                coached_agent_id = agent_id_map[coached_display_name]
            with col2:
                benchmark_options = [name for name in display_name_list if name != coached_display_name]
                st.session_state.benchmark_select = [agent for agent in st.session_state.benchmark_select if agent in benchmark_options]
                
                benchmark_display_names = st.multiselect("é¸æ“‡æ¨™ç«¿ç¾¤çµ„ (å¯å¤šé¸)", options=benchmark_options, key="benchmark_select")
                benchmark_agent_ids = [agent_id_map[name] for name in benchmark_display_names]
            
            scaling_method_display = st.radio(
                "é›·é”åœ–ç¸®æ”¾æ–¹å¼",
                ('æ’åæ­£è¦åŒ– (ç›¸å°è¡¨ç¾)', 'å°æ•¸æ­£è¦åŒ– (çµ•å°é‡é«”)'),
                index=0,
                horizontal=True,
                help="é¸æ“‡é›·é”åœ–ä¸Šå„æŒ‡æ¨™çš„ç¸®æ”¾æ–¹å¼ã€‚\n\n- **æ’åæ­£è¦åŒ–**: æ ¹æ“šäººå“¡åœ¨è©²æŒ‡æ¨™çš„åœ˜éšŠæ’åé€²è¡Œé¡¯ç¤ºï¼Œå°ˆæ³¨æ–¼ç›¸å°å¼·å¼±é …æ¯”è¼ƒã€‚\n- **å°æ•¸æ­£è¦åŒ–**: æ ¹æ“šæŒ‡æ¨™çš„å¯¦éš›æ•¸å€¼å¤§å°é€²è¡Œé¡¯ç¤ºï¼Œèƒ½åæ˜ é‡é«”ä¸Šçš„å·®ç•°ã€‚"
            )
            scaling_method = 'rank' if 'æ’å' in scaling_method_display else 'log'

            if coached_agent_id and benchmark_agent_ids:
                fig, coached_raw, benchmark_avg_raw = create_coaching_radar_chart(
                    agent_summary_df, 
                    coached_agent_id, 
                    coached_display_name, 
                    benchmark_agent_ids,
                    scaling_method=scaling_method
                )
                st.plotly_chart(fig, use_container_width=True)

                st.subheader("é‡åŒ–æ¯”è¼ƒçŸ©é™£")
                
                comparison_df_raw = pd.DataFrame({
                    "ç¸¾æ•ˆæŒ‡æ¨™": [REVERSE_METRICS_TRANSLATION.get(i, i) for i in coached_raw.index],
                    f"å—è¼”å°äººå“¡ ({coached_display_name})": coached_raw.values,
                    "æ¨™ç«¿ç¾¤çµ„å¹³å‡": benchmark_avg_raw.values
                })
                comparison_df_raw['å·®è·'] = comparison_df_raw.iloc[:, 1] - comparison_df_raw.iloc[:, 2]
                
                display_df = comparison_df_raw.copy()
                
                time_metric_name = REVERSE_METRICS_TRANSLATION[METRIC_TOTAL_TALK_TIME]
                if time_metric_name in display_df['ç¸¾æ•ˆæŒ‡æ¨™'].values:
                    time_idx = display_df.index[display_df['ç¸¾æ•ˆæŒ‡æ¨™'] == time_metric_name][0]
                    for col in [f"å—è¼”å°äººå“¡ ({coached_display_name})", "æ¨™ç«¿ç¾¤çµ„å¹³å‡", "å·®è·"]:
                         display_df.loc[time_idx, col] = format_seconds_to_hms(display_df.loc[time_idx, col])
                
                def calculate_gap_colors(df_raw, df_display):
                    colors = {}
                    cost_metrics_display = [] 
                    for index, row in df_raw.iterrows():
                        metric = row['ç¸¾æ•ˆæŒ‡æ¨™']
                        gap = row['å·®è·']
                        color = ''
                        if pd.notna(gap):
                            if metric in cost_metrics_display:
                                color = 'green' if gap < 0 else 'red'
                            else:
                                color = 'green' if gap > 0 else 'red'
                        colors[df_display.index[index]] = f'color: {color}'
                    return colors
                
                gap_colors = calculate_gap_colors(comparison_df_raw, display_df)
                
                st.dataframe(
                    display_df.style.apply(lambda s: s.map(gap_colors), subset=['å·®è·'])
                                  .format({
                                      f"å—è¼”å°äººå“¡ ({coached_display_name})": conditional_format,
                                      "æ¨™ç«¿ç¾¤çµ„å¹³å‡": conditional_format,
                                      "å·®è·": conditional_format,
                                  }, na_rep='-'),
                    use_container_width=True,
                    hide_index=True
                )
            else:
                st.warning("è«‹é¸æ“‡ä¸€ä½å—è¼”å°äººå“¡å’Œè‡³å°‘ä¸€ä½æ¨™ç«¿çµ„æˆå“¡ä»¥ç”Ÿæˆåœ–è¡¨ã€‚")
        else:
            st.info("åœ¨é¸å®šçš„æ¢ä»¶ä¸‹ï¼Œéœ€è¦è‡³å°‘å…©ä½å‚¬æ”¶å“¡çš„æ•¸æ“šæ‰èƒ½é€²è¡Œæ¯”è¼ƒã€‚")

    with tab4:
        st.header("å‚¬å“¡æ·±åº¦å‰–æ (Agent Deep Dive)")
        st.write("æ­¤æ¨¡çµ„æ·±å…¥åˆ†æå–®ä¸€å‚¬æ”¶å“¡çš„å·¥ä½œæ¨¡å¼èˆ‡ç”¢å‡ºç‰¹å¾µï¼Œä¸¦èˆ‡æ¨™ç«¿ç¾¤çµ„é€²è¡Œæ¯”è¼ƒï¼Œä»¥åˆ©æ–¼è­˜åˆ¥å…¶å·¥ä½œå‹æ…‹èˆ‡æ•ˆç‡ã€‚")

        if not filtered_df.empty:
            agent_select_df_deep_dive = filtered_df[[COL_AGENT_ID, COL_AGENT_NAME]].drop_duplicates()
            agent_select_df_deep_dive[COL_DISPLAY_NAME] = agent_select_df_deep_dive[COL_AGENT_ID] + " (" + agent_select_df_deep_dive[COL_AGENT_NAME] + ")"
            agent_id_map_deep_dive = agent_select_df_deep_dive.set_index(COL_DISPLAY_NAME)[COL_AGENT_ID]
            display_name_list_deep_dive = sorted(agent_select_df_deep_dive[COL_DISPLAY_NAME].unique())

            if display_name_list_deep_dive:
                # --- CODE MODIFICATION START ---
                
                # å‹•æ…‹å»ºç«‹åˆ†ææŒ‡æ¨™é¸é …
                analysis_metric_options = ['ç¸½æ’¥æ‰“æ¬¡æ•¸']
                if st.session_state.get('has_connected_calls_data'):
                    analysis_metric_options.append('ç¸½æ¥é€šæ¬¡æ•¸')
                if st.session_state.get('has_talk_time_data'):
                    analysis_metric_options.append('é€šè©±æ™‚é•·')
                
                metric_to_analyze = st.radio("é¸æ“‡åˆ†ææŒ‡æ¨™", options=analysis_metric_options, horizontal=True, key="deep_dive_radio")
                
                # æ ¹æ“šé¸æ“‡çš„æŒ‡æ¨™ï¼Œå‹•æ…‹è¨­å®šé–¾å€¼æ»‘æ¡¿
                if metric_to_analyze == 'ç¸½æ’¥æ‰“æ¬¡æ•¸':
                    max_val_col = COL_CALLS_IN_WINDOW
                    slider_label = f"è¨­å®šç´å…¥åˆ†æçš„å–®æ¡ˆæœ€å¤§{metric_to_analyze}"
                    default_val = 40
                elif metric_to_analyze == 'ç¸½æ¥é€šæ¬¡æ•¸':
                    max_val_col = COL_CONNECTED_CALLS_IN_WINDOW
                    slider_label = f"è¨­å®šç´å…¥åˆ†æçš„å–®æ¡ˆæœ€å¤§{metric_to_analyze}"
                    default_val = 20
                else: # é€šè©±æ™‚é•·
                    max_val_col = COL_TALK_TIME_IN_WINDOW
                    slider_label = f"è¨­å®šç´å…¥åˆ†æçš„å–®æ¡ˆæœ€å¤§{metric_to_analyze}(ç§’)"
                    default_val = 600 # é è¨­10åˆ†é˜
                
                max_val = int(date_filtered_raw_df[max_val_col].max())
                threshold = st.slider(slider_label, min_value=1, max_value=max_val if max_val > 0 else 1, value=min(default_val, max_val) if max_val > 0 else 1, step=1, disabled=(max_val == 0))

                if 'deep_dive_benchmark' not in st.session_state:
                    st.session_state.deep_dive_benchmark = []

                col1, col2 = st.columns(2)
                with col1:
                    selected_agent_display_name = st.selectbox("é¸æ“‡è¦æ·±åº¦å‰–æçš„å‚¬å“¡", options=display_name_list_deep_dive, key="deep_dive_agent")
                    selected_agent_id = agent_id_map_deep_dive[selected_agent_display_name]
                with col2:
                    benchmark_options = [name for name in display_name_list_deep_dive if name != selected_agent_display_name]
                    st.session_state.deep_dive_benchmark = [agent for agent in st.session_state.deep_dive_benchmark if agent in benchmark_options]

                    benchmark_display_names = st.multiselect("é¸æ“‡æ¯”è¼ƒæ¨™ç«¿ç¾¤çµ„ (å¯å¤šé¸)", options=benchmark_options, key="deep_dive_benchmark")
                    benchmark_ids = [agent_id_map_deep_dive[name] for name in benchmark_display_names]

                # å»ºç«‹ä¸€å€‹åˆ†é æˆ–æ¬„ä½ä¾†ä¸¦æ’é¡¯ç¤ºåœ–è¡¨
                chart_col1, chart_col2 = st.columns(2)

                with chart_col1:
                    # ä½¿ç”¨é‡æ§‹å¾Œçš„å‡½å¼
                    st.plotly_chart(create_agent_deep_dive_distribution_chart(date_filtered_raw_df, selected_agent_id, benchmark_ids, selected_agent_display_name, threshold, metric_to_analyze), use_container_width=True)
                
                with chart_col2:
                    st.plotly_chart(create_payment_distribution_chart(date_filtered_raw_df, selected_agent_id, benchmark_ids, selected_agent_display_name), use_container_width=True)
                
                st.markdown("---")
                
                st.subheader("ç¸¾æ•ˆç¸½çµæ¯”è¼ƒ")

                # 1. å–å¾—ä¸¦é¡¯ç¤ºè¢«åˆ†æäººå“¡çš„æ•¸æ“š
                agent_summary_data = agent_summary_df[agent_summary_df[COL_AGENT_ID] == selected_agent_id]
                
                if not agent_summary_data.empty:
                    st.markdown(f"**åˆ†æäººå“¡: {selected_agent_display_name}**")
                    kpi_cols = st.columns(3)
                    kpi_cols[0].metric("æœŸé–“å‚¬å›ç¸½é¡", f"${agent_summary_data[METRIC_TOTAL_COLLECTIONS].iloc[0]:,.0f}")
                    kpi_cols[1].metric("æœŸé–“è™•ç†æ¡ˆä»¶æ•¸", f"{agent_summary_data[METRIC_TOTAL_CASES].iloc[0]:,.0f}")
                    
                    # é¡¯ç¤ºèˆ‡åˆ†ææŒ‡æ¨™ç›¸é—œçš„å¹³å‡å€¼
                    if st.session_state.get('has_talk_time_data'):
                         avg_talk_time = (agent_summary_data[METRIC_TOTAL_TALK_TIME].iloc[0] / agent_summary_data[METRIC_TOTAL_CASES].iloc[0]) if agent_summary_data[METRIC_TOTAL_CASES].iloc[0] > 0 else 0
                         kpi_cols[2].metric("å¹³å‡é€šè©±æ™‚é•·/æ¡ˆ", f"{avg_talk_time:.2f} ç§’")
                    else:
                         kpi_cols[2].metric("å¹³å‡æ’¥æ‰“æ¬¡æ•¸/æ¡ˆ", f"{agent_summary_data[METRIC_AVG_TOUCHES].iloc[0]:.2f}")

                else:
                    st.warning("æ‰¾ä¸åˆ°è©²äººå“¡çš„ç¸¾æ•ˆæ‘˜è¦æ•¸æ“šã€‚")

                # 2. å¦‚æœæœ‰é¸æ“‡æ¨™ç«¿ç¾¤çµ„ï¼Œå‰‡è¨ˆç®—ä¸¦é¡¯ç¤ºå…¶å¹³å‡æ•¸æ“š
                if benchmark_ids:
                    benchmark_summary_df = agent_summary_df[agent_summary_df[COL_AGENT_ID].isin(benchmark_ids)]
                    
                    if not benchmark_summary_df.empty:
                        st.markdown("---") # è¦–è¦ºåˆ†éš”ç·š
                        st.markdown("**æ¨™ç«¿ç¾¤çµ„å¹³å‡ç¸¾æ•ˆ**")
                        
                        # è¨ˆç®—æ¨™ç«¿ç¾¤çµ„çš„äººå‡æŒ‡æ¨™
                        avg_collections = benchmark_summary_df[METRIC_TOTAL_COLLECTIONS].mean()
                        avg_cases = benchmark_summary_df[METRIC_TOTAL_CASES].mean()
                        avg_touches = benchmark_summary_df[METRIC_AVG_TOUCHES].mean()
                        avg_connected_touches = benchmark_summary_df[METRIC_AVG_CONNECTED_TOUCHES].mean()
                        avg_talk_time_per_case = (benchmark_summary_df[METRIC_TOTAL_TALK_TIME].sum() / benchmark_summary_df[METRIC_TOTAL_CASES].sum()) if benchmark_summary_df[METRIC_TOTAL_CASES].sum() > 0 else 0


                        # é¡¯ç¤ºæŒ‡æ¨™
                        kpi_cols_bench = st.columns(3)
                        kpi_cols_bench[0].metric("äººå‡å‚¬å›ç¸½é¡", f"${avg_collections:,.0f}")
                        kpi_cols_bench[1].metric("äººå‡è™•ç†æ¡ˆä»¶æ•¸", f"{avg_cases:.2f}")

                        if st.session_state.get('has_talk_time_data'):
                            kpi_cols_bench[2].metric("äººå‡é€šè©±æ™‚é•·/æ¡ˆ", f"{avg_talk_time_per_case:.2f} ç§’")
                        else:
                            kpi_cols_bench[2].metric("äººå‡æ’¥æ‰“æ¬¡æ•¸/æ¡ˆ", f"{avg_touches:.2f}")

                # --- CODE MODIFICATION END ---
            else:
                st.info("è«‹åœ¨å´é‚Šæ¬„é¸æ“‡åŒ…å«å‚¬å“¡çš„çµ„åˆ¥ä»¥é€²è¡Œæ·±åº¦å‰–æã€‚")
        else:
            st.info("åœ¨é¸å®šçš„æ¢ä»¶ä¸‹æ²’æœ‰æ•¸æ“šå¯é¡¯ç¤ºã€‚")
else:
    st.error("æ•¸æ“šè¼‰å…¥å¤±æ•—ï¼Œå„€è¡¨æ¿ç„¡æ³•å•Ÿå‹•ã€‚è«‹æª¢æŸ¥ä¸»æ§å°ä¸­çš„éŒ¯èª¤è¨Šæ¯æˆ– `secrets.toml` è¨­å®šã€‚")
